"""íšŒì‹ ì¥ì†Œ ì¶”ì²œ ì—ì´ì „íŠ¸ (LangGraph)"""

from typing import Dict, List, Any, TypedDict
from langgraph.graph import StateGraph, END
from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from app.services.naver_search_service import NaverSearchService
from app.models import RestaurantRecommendation
from app.config import settings
from app.logger import get_logger

# ë¡œê±° ì´ˆê¸°í™”
logger = get_logger("restaurant_agent")


class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ"""
    user_query: str
    query_type: str
    location: str
    preferences: Dict[str, Any]
    search_results: List[RestaurantRecommendation]
    recommendations: List[RestaurantRecommendation]
    response: str


class RestaurantRecommendationAgent:
    """íšŒì‹ ì¥ì†Œ ì¶”ì²œ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        logger.info("RestaurantRecommendationAgent ì´ˆê¸°í™” ì‹œì‘")
        
        # LLM ì´ˆê¸°í™”
        try:
            logger.info(f"Azure OpenAI ì„¤ì • - Endpoint: {settings.azure_openai_endpoint}")
            logger.info(f"Deployment: {settings.azure_openai_deployment_name}")
            logger.info(f"API Version: {settings.azure_openai_api_version}")
            logger.info(f"API Key (ì²« 10ì): {settings.azure_openai_api_key[:10]}...")
            
            # ì„¤ì • ê²€ì¦
            if not settings.azure_openai_api_key or settings.azure_openai_api_key == "your_azure_openai_api_key":
                raise ValueError("Azure OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            if not settings.azure_openai_endpoint or settings.azure_openai_endpoint == "https://your-resource.openai.azure.com/":
                raise ValueError("Azure OpenAI ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            if not settings.azure_openai_deployment_name or settings.azure_openai_deployment_name == "your_deployment_name":
                raise ValueError("Azure OpenAI ë°°í¬ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            self.llm = AzureChatOpenAI(
                azure_deployment=settings.azure_openai_deployment_name,
                azure_endpoint=settings.azure_openai_endpoint,
                api_key=settings.azure_openai_api_key,
                api_version=settings.azure_openai_api_version,
            )
            logger.info("LLM ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise
        
        # ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        try:
            self.search_service = NaverSearchService()
            logger.info("ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise
        
        # ê·¸ë˜í”„ êµ¬ì„±
        try:
            self.graph = self._build_graph()
            logger.info("ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ê·¸ë˜í”„ êµ¬ì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise
        
        logger.info("RestaurantRecommendationAgent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_graph(self) -> StateGraph:
        """LangGraph ê·¸ë˜í”„ êµ¬ì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("classify_query", self._classify_query)
        workflow.add_node("extract_preferences", self._extract_preferences)
        workflow.add_node("search_restaurants", self._search_restaurants)
        workflow.add_node("generate_recommendations", self._generate_recommendations)
        workflow.add_node("format_response", self._format_response)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("classify_query")
        workflow.add_edge("classify_query", "extract_preferences")
        workflow.add_edge("extract_preferences", "search_restaurants")
        workflow.add_edge("search_restaurants", "generate_recommendations")
        workflow.add_edge("generate_recommendations", "format_response")
        workflow.add_edge("format_response", END)
        
        return workflow.compile()
    
    async def _classify_query(self, state: AgentState) -> AgentState:
        """ì¿¼ë¦¬ ë¶„ë¥˜: ì¼ë°˜ ì§ˆì˜ì¸ì§€ íšŒì‹ ì¥ì†Œ ì¶”ì²œì¸ì§€ íŒë‹¨"""
        logger.info(f"ì¿¼ë¦¬ ë¶„ë¥˜ ì‹œì‘: {state['user_query'][:100]}...")
        
        try:
            messages = [
                SystemMessage(content="""
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
                1. "restaurant_recommendation" - íšŒì‹ ì¥ì†Œ ì¶”ì²œ ìš”ì²­
                2. "general" - ì¼ë°˜ì ì¸ ì§ˆë¬¸
                
                íšŒì‹, ì‹ë‹¹, ë§›ì§‘, íšŒì‹ ì¥ì†Œ, ì‹ì‚¬, ì ì‹¬, ì €ë… ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ "restaurant_recommendation"ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
                """),
                HumanMessage(content=state["user_query"])
            ]
            
            logger.info("ì¿¼ë¦¬ ë¶„ë¥˜ LLM í˜¸ì¶œ ì‹œì‘")
            import asyncio
            try:
                response = await asyncio.wait_for(
                    self.llm.ainvoke(messages), 
                    timeout=60.0
                )
                logger.info("ì¿¼ë¦¬ ë¶„ë¥˜ LLM í˜¸ì¶œ ì™„ë£Œ")
            except Exception as llm_error:
                logger.error(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(llm_error).__name__}: {str(llm_error)}")
                logger.error(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´: {repr(llm_error)}")
                raise
            
            query_type = response.content.strip().lower()
            logger.info(f"ì¿¼ë¦¬ ë¶„ë¥˜ ê²°ê³¼: {query_type}")
            
            return {
                **state,
                "query_type": query_type
            }
        except asyncio.TimeoutError:
            logger.error("ì¿¼ë¦¬ ë¶„ë¥˜ LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (15ì´ˆ)")
            # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ë¶„ë¥˜ ì‹œë„
            query_lower = state["user_query"].lower()
            if any(keyword in query_lower for keyword in ["íšŒì‹", "ì‹ë‹¹", "ë§›ì§‘", "íšŒì‹ ì¥ì†Œ", "ì‹ì‚¬", "ì ì‹¬", "ì €ë…", "ì‚¼ê²¹ì‚´"]):
                query_type = "restaurant_recommendation"
            else:
                query_type = "general"
            logger.info(f"íƒ€ì„ì•„ì›ƒ í›„ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼: {query_type}")
            return {
                **state,
                "query_type": query_type
            }
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            logger.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {repr(e)}")
            # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ë¶„ë¥˜ ì‹œë„
            query_lower = state["user_query"].lower()
            if any(keyword in query_lower for keyword in ["íšŒì‹", "ì‹ë‹¹", "ë§›ì§‘", "íšŒì‹ ì¥ì†Œ", "ì‹ì‚¬", "ì ì‹¬", "ì €ë…", "ì‚¼ê²¹ì‚´"]):
                query_type = "restaurant_recommendation"
            else:
                query_type = "general"
            logger.info(f"ì˜¤ë¥˜ í›„ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼: {query_type}")
            return {
                **state,
                "query_type": query_type
            }
    
    async def _extract_preferences(self, state: AgentState) -> AgentState:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
        if state["query_type"] != "restaurant_recommendation":
            return state
        
        logger.info("ì„ í˜¸ë„ ì¶”ì¶œ ì‹œì‘")
        
        try:
            messages = [
                SystemMessage(content="""
                ì‚¬ìš©ìì˜ íšŒì‹ ì¥ì†Œ ì¶”ì²œ ìš”ì²­ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ì‘ë‹µí•˜ì„¸ìš”:
                {
                    "location": "ì§€ì—­ ë˜ëŠ” ì£¼ì†Œ",
                    "budget": "ì˜ˆì‚° ìˆ˜ì¤€ (1-4)",
                    "cuisine_type": "ìŒì‹ ì¢…ë¥˜",
                    "group_size": "ì¸ì›ìˆ˜",
                    "occasion": "íšŒì‹ ëª©ì ",
                    "special_requirements": "íŠ¹ë³„ ìš”êµ¬ì‚¬í•­"
                }
                
                ì •ë³´ê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° nullë¡œ ì„¤ì •í•˜ì„¸ìš”.
                """),
                HumanMessage(content=state["user_query"])
            ]
            
            logger.info("ì„ í˜¸ë„ ì¶”ì¶œ LLM í˜¸ì¶œ ì‹œì‘")
            import asyncio
            response = await asyncio.wait_for(
                self.llm.ainvoke(messages), 
                timeout=60.0
            )
            logger.info("ì„ í˜¸ë„ ì¶”ì¶œ LLM í˜¸ì¶œ ì™„ë£Œ")
            
            # JSON íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì•ˆì „í•œ íŒŒì‹± í•„ìš”)
            try:
                import json
                preferences = json.loads(response.content)
                logger.info(f"ì¶”ì¶œëœ ì„ í˜¸ë„: {preferences}")
            except Exception as parse_error:
                logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {parse_error}")
                preferences = {
                    "location": "ì„œìš¸",
                    "budget": None,
                    "cuisine_type": None,
                    "group_size": None,
                    "occasion": None,
                    "special_requirements": None
                }
            
            return {
                **state,
                "preferences": preferences,
                "location": preferences.get("location", "ì„œìš¸")
            }
            
        except asyncio.TimeoutError:
            logger.error("ì„ í˜¸ë„ ì¶”ì¶œ LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (15ì´ˆ)")
            # ê¸°ë³¸ ì„ í˜¸ë„ ì„¤ì •
            preferences = {
                "location": "ì„œìš¸",
                "budget": None,
                "cuisine_type": None,
                "group_size": None,
                "occasion": None,
                "special_requirements": None
            }
            return {
                **state,
                "preferences": preferences,
                "location": "ì„œìš¸"
            }
        except Exception as e:
            logger.error(f"ì„ í˜¸ë„ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            # ê¸°ë³¸ ì„ í˜¸ë„ ì„¤ì •
            preferences = {
                "location": "ì„œìš¸",
                "budget": None,
                "cuisine_type": None,
                "group_size": None,
                "occasion": None,
                "special_requirements": None
            }
            return {
                **state,
                "preferences": preferences,
                "location": "ì„œìš¸"
            }
    
    async def _search_restaurants(self, state: AgentState) -> AgentState:
        """ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ í†µí•œ ì‹ë‹¹ ê²€ìƒ‰"""
        if state["query_type"] != "restaurant_recommendation":
            return state
        
        preferences = state["preferences"]
        logger.info(f"ì‹ë‹¹ ê²€ìƒ‰ ì‹œì‘ - ìœ„ì¹˜: {state['location']}, ì„ í˜¸ë„: {preferences}")
        
        try:
            # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
            keyword = preferences.get("cuisine_type")
            price_level = preferences.get("budget")
            rating = 4.0  # ìµœì†Œ í‰ì 
            
            logger.info(f"ê²€ìƒ‰ íŒŒë¼ë¯¸í„° - í‚¤ì›Œë“œ: {keyword}, ê°€ê²©ëŒ€: {price_level}, ìµœì†Œí‰ì : {rating}")
            
            search_results = await self.search_service.search_restaurants(
                location=state["location"],
                keyword=keyword,
                cuisine_type=preferences.get("cuisine_type"),
                price_level=price_level,
                rating=rating
            )
            
            logger.info(f"ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {len(search_results)}")
            for i, result in enumerate(search_results[:3]):  # ìƒìœ„ 3ê°œë§Œ ë¡œê·¸
                logger.info(f"ê²€ìƒ‰ ê²°ê³¼ {i+1}: {result.name} (í‰ì : {result.rating})")
            
            return {
                **state,
                "search_results": search_results
            }
        except Exception as e:
            logger.error(f"ì‹ë‹¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return {
                **state,
                "search_results": []
            }
    
    async def _generate_recommendations(self, state: AgentState) -> AgentState:
        """LLMì„ í†µí•œ ì¶”ì²œ ìƒì„±"""
        if state["query_type"] != "restaurant_recommendation":
            return state
        
        search_results = state["search_results"]
        preferences = state["preferences"]
        
        if not search_results:
            return {
                **state,
                "recommendations": [],
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§€ì—­ì—ì„œ ì í•©í•œ ì‹ë‹¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        restaurants_text = "\n".join([
            f"- {r.name} (í‰ì : {r.rating}, ì£¼ì†Œ: {r.address}, ì„¤ëª…: {r.description})"
            for r in search_results[:10]  # ìƒìœ„ 10ê°œë§Œ
        ])
        
        messages = [
            SystemMessage(content=f"""
            ë‹¤ìŒ ì‹ë‹¹ ëª©ë¡ì—ì„œ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ìµœê³ ì˜ ì¶”ì²œ 3-5ê°œë¥¼ ì„ íƒí•˜ê³  ì„¤ëª…í•˜ì„¸ìš”.
            ê° ì‹ë‹¹ ì´ë¦„ì€ ì •í™•í•œ ì´ë¦„ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ë‹¹ì˜ ì„¤ëª… ë¶€ë¶„ì— ì‹ë‹¹ ì´ë¦„ì´ ìˆë‹¤ë©´ ê·¸ ì´ë¦„ì„ ì‹ë‹¹ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

            ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­:
            - ì§€ì—­: {preferences.get('location', 'ì„œìš¸')}
            - ì˜ˆì‚°: {preferences.get('budget', 'ì œí•œì—†ìŒ')}
            - ìŒì‹ ì¢…ë¥˜: {preferences.get('cuisine_type', 'ì œí•œì—†ìŒ')}
            - ì¸ì›ìˆ˜: {preferences.get('group_size', 'ì œí•œì—†ìŒ')}
            - ëª©ì : {preferences.get('occasion', 'ì¼ë°˜ íšŒì‹')}
            - íŠ¹ë³„ ìš”êµ¬ì‚¬í•­: {preferences.get('special_requirements', 'ì—†ìŒ')}
            
            ê° ì¶”ì²œì— ëŒ€í•´ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
            1. ì‹ë‹¹ëª…
            2. ì¶”ì²œ ì´ìœ 
            3. íŠ¹ì§• ë° ì¥ì 
            4. ì£¼ì†Œ ë° ì—°ë½ì²˜ (ìˆëŠ” ê²½ìš°)
            """),
            HumanMessage(content=f"ê²€ìƒ‰ëœ ì‹ë‹¹ ëª©ë¡:\n{restaurants_text}")
        ]
        
        logger.info("LLM í˜¸ì¶œ ì‹œì‘")
        try:
            timeout = 300.0
            import asyncio
            response = await asyncio.wait_for(
                self.llm.ainvoke(messages), 
                timeout=timeout
            )
            logger.info("LLM í˜¸ì¶œ ì™„ë£Œ")
        except asyncio.TimeoutError:
            logger.error(f"LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            return {
                **state,
                "recommendations": search_results[:3],  # ê¸°ë³¸ ì¶”ì²œ
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ë¶„ì„ ì¤‘ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì‹ë‹¹ ì¤‘ ìƒìœ„ 3ê°œë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤."
            }
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return {
                **state,
                "recommendations": search_results[:3],  # ê¸°ë³¸ ì¶”ì²œ
                "response": f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì‹ë‹¹ ì¤‘ ìƒìœ„ 3ê°œë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. (ì˜¤ë¥˜: {str(e)})"
            }
        
        # ì¶”ì²œ ê²°ê³¼ë¥¼ ì›ë³¸ ë°ì´í„°ì™€ ë§¤ì¹­
        recommendations = []
        for restaurant in search_results[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶”ì²œ
            recommendations.append(restaurant)
        
        return {
            **state,
            "recommendations": recommendations,
            "response": response.content
        }
    
    async def _format_response(self, state: AgentState) -> AgentState:
        """ìµœì¢… ì‘ë‹µ í¬ë§·íŒ…"""
        if state["query_type"] != "restaurant_recommendation":
            return {
                **state,
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. íšŒì‹ ì¥ì†Œ ì¶”ì²œ ê¸°ëŠ¥ë§Œ ì§€ì›í•©ë‹ˆë‹¤. íšŒì‹ ì¥ì†Œì— ëŒ€í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
            }
        
        recommendations = state["recommendations"]
        response_text = state["response"]
        
        # Teams ì ì‘í˜• ì¹´ë“œ í˜•íƒœë¡œ í¬ë§·íŒ…
        formatted_response = f"""
                                ğŸ½ï¸ **íšŒì‹ ì¥ì†Œ ì¶”ì²œ**

                                {response_text}

                                **ì¶”ì²œ ì‹ë‹¹ ëª©ë¡:**
                                """
        
        for i, restaurant in enumerate(recommendations, 1):
            formatted_response += f"""
                                    {i}. **{restaurant.name}**
                                    - í‰ì : {restaurant.rating}â­
                                    - ì£¼ì†Œ: {restaurant.address}
                                    - ì „í™”: {restaurant.phone_number or 'ì •ë³´ ì—†ìŒ'}
                                    """
        
        return {
            **state,
            "response": formatted_response
        }
    
    async def process_query(self, user_query: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬"""
        initial_state = {
            "user_query": user_query,
            "query_type": "",
            "location": "",
            "preferences": {},
            "search_results": [],
            "recommendations": [],
            "response": ""
        }
        
        result = await self.graph.ainvoke(initial_state)
        
        return {
            "query_type": result["query_type"],
            "recommendations": result["recommendations"],
            "response": result["response"]
        }
